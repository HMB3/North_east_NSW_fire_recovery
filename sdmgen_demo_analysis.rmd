---
title: "sdmgen : a pacakge for rapidly estimating multiple species ranges and habit sutiability"
authors: "Hugh Burley, John Baumgartner, Linda Beaumont"
date: "March 2020"
output:
  html_document:
  toc: true             # Table of content true
toc_depth: 4            # Up to three depths of headings (specified by #, ## and html_document
toc_float: true
number_sections: false  # If you want number sections at each table header
theme: united           # Many options for theme, this one is my favorite.
highlight: tango        # Specifies the syntax highlighting style
css: styles.css
revealjs::revealjs_presentation:
  dev: 'svg'
css: styles.css
self_contained: false
reveal_plugins: ["notes", "search"]
reveal_options:
  slideNumber: true
previewLinks: true
word_document:
  always_allow_html: yes
---


<style>
p.caption {
font-size: 6;
}
</style>



\

The text and code below summarises a workflow in R that can be used to relatively rapidly assess the effect
of climate change on a species within Australia, from downloading occurrence records, through to creating
maps of predicted climatic suitability across Australia at 1km*1km resolution. An example of this work is 
published in Science of the Total Environment ::

\

Burley, H., Beaumont, L.J., Ossola, A., et al. (2019) Substantial declines in urban tree habitat predicted 
under climate change. Science of The Total Environment, 685, 451-462.

https://www.sciencedirect.com/science/article/pii/S0048969719323289#f0030 


\


### To install, run :

```{r message=FALSE, echo=FALSE, warning=FALSE}

## The package should import all the required packges
devtools::install_github("HMB3/sdmgen")
library(sdmgen)


## Load the required packages
data("sdmgen_packages")
sapply(sdmgen_packages, require, character.only = TRUE)


```


\


# STEP 1 :: Download species occurrence data


\

The backbone of the R workflow is a list of (taxonomically Ridgey Didge!) species names 
that we supply. The analysis is designed to process data for one species at a time, 
allowing species results to be updated as required. We can demonstrate the workflow 
using a sample of 10 plant species from the Stoten publication above. 


\

```{r message=FALSE, echo=FALSE, warning=FALSE}

## Use the first 10 plant species in the Stoten list
data("plant.spp")
analysis_spp <- plant.spp[1:10]
analysis_spp

```

\

Also load the shapefiles needed for running the analysis functions. This workfow uses three shapefiles :
Australia, the world and the Significant Urban areas of Australia (or SUAs). The SUAs are taken from
the ABS : https://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.004July%202016?OpenDocument.
The Koppen data are from CliMond, centred on 1975 : https://www.climond.org/Core/Authenticated/KoppenGeiger.aspx

```{r message=FALSE, echo=FALSE, warning=FALSE}

## Three shapefiles used in the analysis
data('AUS')
data('LAND')
data('Koppen_shp')
data('SUA')

```

\

This species list is then supplied to a series of functions to calculate enviromnetal ranges and habitat 
suitability. The initial functions download all species records from the Atlas and living Australia
(https://www.ala.org.au/) and the Global Biodiversity Information Facility (GBIF, https://www.gbif.org/). 
It downloads the species data as individual .Rdata files to the specified folders, which must exist first, 
without returning anything. The functions are separated because the ALA and GBIF columns are slightly 
different, but both data sources are needed to properly quantify species ranges.

\

The package functions expect these folders, create them if they don't exist

```{r message=FALSE, echo=FALSE, warning=FALSE}

## The functions expect these folders, create them if they don't exist
ALA_dir     <- './data/ALA'
GBIF_dir    <- './data/GBIF'


## Results dir
back_dir    <- './output/maxent/back_sel_models'
full_dir    <- './output/maxent/full_models'
results_dir <- './output/results'

## Checking dir 
check_dir <-'./data/GBIF/Check_plots/'


## Create ALA subfolder
if(!dir.exists(ALA_dir)) {
  message('Creating ALA directory for ', species)
  dir.create(ALA_dir) } else {
    'ALA directory already exists'}

## Create GBIF subfolder
if(!dir.exists(GBIF_dir)) {
  message('Creating GBIF directory for ', species)
  dir.create(GBIF_dir) } else {
    'GBIF directory already exists'}

## Create BS subfolder
if(!dir.exists(back_dir)) {
  message('Creating Backwards selected directory for ', species)
  dir.create(back_dir) } else {
    'Backwards selection directory already exists'}

## Create Full subfolder
if(!dir.exists(full_dir)) {
  message('Creating Full directory for ', species)
  dir.create(full_dir) } else {
    'Full directory already exists'}

## Create Results subfolder
if(!dir.exists(results_dir)) {
  message('Creating results directory for ', species)
  dir.create(results_dir) } else {
    'Results directory already exists'}


## Create Checking subfolder
if(!dir.exists(check_dir)) {
  message('Creating results directory for ', species)
  dir.create(check_dir) } else {
    'Checking directory already exists'}


```

\

Download GBIF and ALA occurrence data for each species

```{r message=FALSE, echo=FALSE, warning=FALSE}

## Download GBIF occurrence data for each species
download_GBIF_all_species(species_list  = analysis_spp,
                          download_path = "./data/GBIF/",
                          download_limit = 20000)


## Download ALA occurrence data for each species
download_ALA_all_species(species_list  = analysis_spp,
                         your_email    = 'hugh.burley@gmail.com',
                         download_path = "./data/ALA/",
                         download_limit = 20000)

``` 

\

# STEP 2 :: Combine species occurrence data

\

The next function combines ALA and GBIF records, filtering them to records on land, 
and recorded after 1950. The climate (i.e. raster) data  used can be any worldclim layer.

\

First, get some global climate data from worldclim. You need to create a 'data' folder 
in the project directory.

\

```{r message=FALSE, echo=FALSE, warning=FALSE}

## Download global raster for minimum temperature 
worldclim_climate     <- raster::getData('worldclim', var = 'bio', res = 2.5, path = './data')
worldclim_annual_temp <- raster::stack("./data/wc2-5/bio1.bil")
sp::plot(worldclim_climate[["bio1"]])

``` 

\

Then trim the occurrence records to those inside the raster boundaries (i.e. species records in the ocean
according to the Raster boundaries will be excluded)

\

```{r message=FALSE, echo=FALSE, warning=FALSE}

## Combine ALA data, and filter to records on land taken > 1950
## The climate data is the worldclim version 1.0
ALA.LAND = combine_ala_records(species_list      = analysis_spp,
                               records_path      = "./data/ALA/",
                               records_extension = "_ALA_records.RData",
                               record_type       = "ALA",
                               keep_cols         = ALA_keep,
                               world_raster      = worldclim_annual_temp)


## Combine GBIF data and filter to records on land taken > 1950
GBIF.LAND = combine_gbif_records(species_list      = analysis_spp,
                                 records_path      = "./data/GBIF/",
                                 records_extension = "_GBIF_records.RData",
                                 record_type       = "GBIF",
                                 keep_cols         = gbif_keep,
                                 world_raster      = worldclim_annual_temp)

``` 

\

# STEP 3 :: extract environmental values

\

The next function in the workflow combines occurrence files from ALA and GBIF into one table, 
and extracts environmental values. It assumes that both files come from the combine_ala_records 
and combine_gbif_records functions.


\

First create a template raster of 1km * 1km cells using the downloaded worlclim data.
This raster is used to filter records to 1 per one 1km cell. This raster needs to have
the same extent and resolution of the data used to analyse the species distributions.
Fetch a cup of tea this takes ages.....

```{r message=FALSE, echo=FALSE, warning=FALSE}


## Use gdal to create a template raster in WGS84
template.raster.1km.WGS84 <- gdalwarp("./data/wc2-5/bio1.bil",
                                      tempfile(fileext = '.bil'),
                                      t_srs = '+proj=moll +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs',
                                      output_Raster = TRUE,
                                      tr = c(1000, 1000),
                                      r = "near", dstnodata = '-9999') %>% 
  projectRaster(., crs = '+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0')


## Should be 1km*1km 
xres(template.raster.1km.WGS84)

``` 


\

Note that the order of the raster names in 'world_raster' must match the order of names in env_variables.
In this case, it's simply the biolclim variables (i.e. bio1- bio19)

```{r message=FALSE, echo=TRUE, warning=FALSE}

## Combine GBIF and ALA data, and extract environmental values
COMBO.RASTER.CONVERT = combine_records_extract(ala_df          = ALA.LAND,
                                               gbif_df         = GBIF.LAND,
                                               urban_df        = 'NONE',
                                               thin_records    = TRUE,
                                               template_raster = template.raster.1km,
                                               world_raster    = worldclim_climate,
                                               prj             = CRS("+init=epsg:4326"),
                                               species_list    = analysis_spp,
                                               biocl_vars      = bioclim_variables,
                                               env_vars        = env_variables,
                                               worldclim_grids = "TRUE",
                                               save_data       = "FALSE",
                                               save_run        = "TEST_BATS")

``` 

\

# STEP 4 :: Flag institutional outliers

\

The next stage of the process runs a series of cleaning steps. This function takes a data frame of all 
species records, and flag records as institutional or spatial outliers. It uses the CoordinateCleaner 
package https://cran.r-project.org/web/packages/CoordinateCleaner/index.html. It assumes that the 
records data.frame is that returned by the combine_records_extract function.


\


```{r message=FALSE, echo=TRUE, warning=FALSE}

## :: Flag records as institutional or spatial outliers
COORD.CLEAN = coord_clean_records(records    = COMBO.RASTER.CONVERT,
                                  capitals   = 10000,  ## Remove records within 10km  of capitals
                                  centroids  = 5000,   ## Remove records within 5km of country centroids
                                  save_run   = "TEST_SPECIES",
                                  save_data  = "FALSE")
``` 

\

This function takes a data frame of all species records, flags records as spatial outliers (T/F for each 
record in the df), and saves images of the checks for each. Manual cleaning of spatial outliers is very 
tedious, but automated cleaning makes mistakes, so checking is handy It uses the CoordinateCleaner package https://cran.r-project.org/web/packages/CoordinateCleaner/index.html. It assumes that the input dfs are 
those returned by the coord_clean_records function

```{r message=FALSE, echo=TRUE, warning=FALSE}

## Step 4b :: Flag spatial outliers
SPATIAL.CLEAN = check_spatial_outliers(all_df       = COORD.CLEAN,
                                       land_shp     = LAND,
                                       urban_df     = FALSE, 
                                       clean_path   = './data/GBIF/Check_plots/',
                                       spatial_mult = 10,
                                       prj          = CRS("+init=epsg:4326"))
``` 

\

Note that the order of the raster names in 'world_raster' must match the order of names in env_variables.
In this case, it's simply the biolclim variables (i.e. bio1- bio19)

```{r message=FALSE, echo=TRUE, warning=FALSE}

## Step 4c ::Estimate climate niches usign species records
GLOB.NICHE = calc_1km_niches(coord_df     = SPATIAL.CLEAN,
                             prj          = CRS("+init=epsg:4326"),
                             country_shp  = AUS,
                             world_shp    = LAND,
                             kop_shp      = Koppen_shp,
                             species_list = analysis_spp,
                             env_vars     = env_variables,
                             cell_size    = 2,
                             save_run     = "Stoten_EG",
                             data_path    = "./output/results/",
                             save_data    = "TRUE")

``` 

\

Note that the order of the raster names in 'world_raster' must match the order of names in env_variables.
In this case, it's simply the biolclim variables (i.e. bio1- bio19)

```{r message=FALSE, echo=TRUE, warning=FALSE}

## Step 4d :: plot species ranges using histograms and convex hulls for rainfall and temperature distributions
plot_range_histograms(coord_df     = SPATIAL.CLEAN,
                      species_list = analysis_spp,
                      range_path   = check_dir)
``` 


\

# STEP 5 :: Prepare SDM table

\

This function takes a data frame of all species records, and prepares a table in the 'species with data' 
(swd) format for modelling uses the Maxent algorithm. It assumes that the input df is that returned by the 
coord_clean_records function . There is a switch in the function, that adds additional bakground points from 
other taxa, if specified. In this example for bats, we'll just use the species supplied

\

```{r message=FALSE, echo=FALSE, warning=FALSE}

SDM.SPAT.OCC.BG = prepare_sdm_table(coord_df        = SPATIAL.CLEAN,
                                    species_list    = unique(SPATIAL.CLEAN$searchTaxon),
                                    sdm_table_vars  = sdm_table_vars,
                                    save_run        = "Stoten_EG",
                                    read_background = "FALSE",
                                    save_data       = "FALSE",
                                    save_shp        = "FALSE")

``` 


\

# STEP  6 :: Run Global SDMs

\

This function takes a data frame of all species records, and runs a specialised maxent analysis for each species.
It uses the rmaxent package https://github.com/johnbaums/rmaxent
It assumes that the input df is that returned by the prepare_sdm_table function

\

The function uses a rasterised version of the 1975 Koppen raster, and another template raster of the same 
extent (global), resolution (1km*1km) and projection (mollweide) as the analysis data.

\

```{r message=FALSE, echo=FALSE, warning=FALSE}

Koppen_1975_1km  = raster('data/world_koppen/Koppen_1000m_Mollweide54009.tif')


## Use gdal to create a template raster in mollweide
template.raster.1km.mol <- gdalwarp("./data/wc2-5/bio1.bil",
                                    tempfile(fileext = '.bil'),
                                    t_srs = '+proj=moll +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs',
                                    output_Raster = TRUE,
                                    tr = c(1000, 1000),
                                    r = "near", dstnodata = '-9999') 

## Should be 1km*1km 
xres(template.raster.1km.mol)

``` 

\

```{r message=FALSE, echo=FALSE, warning=FALSE}

run_sdm_analysis(species_list            = analysis_spp,
                 maxent_dir              = 'output/maxent/full_models',     
                 bs_dir                  = 'output/maxent/back_sel_models',
                 sdm_df                  = SDM.SPAT.OCC.BG,
                 sdm_predictors          = bs_predictors,
                 backwards_sel           = "TRUE",      
                 template_raster         = template.raster.1km.mol,
                 cor_thr                 = 0.8,  
                 pct_thr                 = 5, 
                 k_thr                   = 4, 
                 
                 min_n                   = 20,  
                 max_bg_size             = 70000,
                 background_buffer_width = 200000,
                 shapefiles              = TRUE,
                 features                = 'lpq',
                 replicates              = 5,
                 responsecurves          = TRUE,
                 country_shp             = AUS,
                 Koppen_zones            = Koppen_zones,
                 Koppen_raster           = Koppen_1975_1km)

``` 


\




